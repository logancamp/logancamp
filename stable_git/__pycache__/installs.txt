git, python 3.9.13 and pytorch 11.7


git lfs install
git clone https://huggingface.co/runwayml/stable-diffusion-v1-5

pip install diffusers==0.12.1
pip install transformers



Models:

stable-diffusion-v1-1: 
237,000 steps at resolution 256x256 on laion2B-en. 194,000 steps at resolution 512x512 on laion-high-resolution (170M examples from LAION-5B with resolution >= 1024x1024).

stable-diffusion-v1-2: 
Resumed from stable-diffusion-v1-1. 515,000 steps at resolution 512x512 on "laion-improved-aesthetics" (a subset of laion2B-en, filtered to images with an original size >= 512x512, estimated aesthetics score > 5.0, and an estimated watermark probability < 0.5. The watermark estimate is from the LAION-5B metadata, the aesthetics score is estimated using an improved aesthetics estimator).

stable-diffusion-v1-3: 
Resumed from stable-diffusion-v1-2 - 195,000 steps at resolution 512x512 on "laion-improved-aesthetics" and 10 % dropping of the text-conditioning to improve classifier-free guidance sampling.

stable-diffusion-v1-4:
Resumed from stable-diffusion-v1-2 - 225,000 steps at resolution 512x512 on "laion-aesthetics v2 5+" and 10 % dropping of the text-conditioning to improve classifier-free guidance sampling.

stable-diffusion-v1-5:
Resumed from stable-diffusion-v1-2 - 595,000 steps at resolution 512x512 on "laion-aesthetics v2 5+" and 10 % dropping of the text-conditioning to improve classifier-free guidance sampling.

stable-diffusion-inpainting:
Resumed from stable-diffusion-v1-5 - then 440,000 steps of inpainting training at resolution 512x512 on â€œlaion-aesthetics v2 5+â€ and 10% dropping of the text-conditioning. For inpainting, the UNet has 5 additional input channels (4 for the encoded masked-image and 1 for the mask itself) whose weights were zero-initialized after restoring the non-inpainting checkpoint. During training, we generate synthetic masks and in 25% mask everything.




https://www.youtube.com/watch?v=a8U7GPEwdEs&ab_channel=ThisCozyStudio\